{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<small><font color=gray>Notebook author: <a href=\"https://www.linkedin.com/in/olegmelnikov/\" target=\"_blank\">Oleg Melnikov</a> , <a href=\"https://www.hse.ru/en/staff/sara/\" target=\"_blank\">Saraa Ali</a> ¬©2025</font></small><hr style=\"margin:0;background-color:silver\">\n",
        "\n",
        "**[<font size=6>üååStellar</font>](https://www.kaggle.com/t/70dd27df0139454ab934bf3ee1d30eb1)**. [**Instructions**](https://colab.research.google.com/drive/1owkYjuRGkx050LQnM3b3yTzd0Dr2XbeV) for running Colabs."
      ],
      "metadata": {
        "id": "q3pqxgX4DxeH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<small>**(Optional) CONSENT.** <mark>[ X ]</mark> We consent to sharing our Colab (after the assignment ends) with other students/instructors for educational purposes. We understand that sharing is optional and this decision will not affect our grade in any way. <font color=gray><i>(If ok with sharing your Colab for educational purposes, leave \"X\" in the check box.)</i></font></small>"
      ],
      "metadata": {
        "id": "_dTfQBUZyNQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive; drive.mount('/content/drive')   # OK to enable, if your kaggle.json is stored in Google Drive"
      ],
      "metadata": {
        "id": "qrogZ_8bD9tZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51a7d3e7-33dd-4cc2-e696-2221410c94f7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8XoC8VqBXGs",
        "outputId": "445ad79f-af43-4c13-c23c-8c4387553fae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/drive/MyDrive/kaggle.json': No such file or directory\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/__init__.py\", line 6, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 434, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method. See setup instructions at https://github.com/Kaggle/kaggle-api/\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/__init__.py\", line 6, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 434, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method. See setup instructions at https://github.com/Kaggle/kaggle-api/\n",
            "unzip:  cannot find or open *.zip, *.zip.zip or *.zip.ZIP.\n",
            "\n",
            "No zipfiles found.\n"
          ]
        }
      ],
      "source": [
        "!pip -q install --upgrade --force-reinstall --no-deps kaggle > log  # upgrade kaggle package (to avoid a warning)\n",
        "!mkdir -p ~/.kaggle                                           # .kaggle folder must contain kaggle.json for kaggle executable to properly authenticate you to Kaggle.com\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json >log  # First, download kaggle.json from kaggle.com (in Account page) and place it in the root of mounted Google Drive\n",
        "!cp kaggle.json ~/.kaggle/kaggle.json > log                   # Alternative location of kaggle.json (without a connection to Google Drive)\n",
        "!chmod 600 ~/.kaggle/kaggle.json                      # give only the owner full read/write access to kaggle.json\n",
        "!kaggle config set -n competition -v  25-hse-stellar       # set the competition context for the next few kaggle API calls. !kaggle config view - shows current settings\n",
        "!kaggle competitions download >> log                          # download competition dataset as a zip file\n",
        "!unzip -o *.zip >> log                                        # Kaggle dataset is copied as a single file and needs to be unzipped.\n",
        "lb =!kaggle competitions leaderboard --show                   # print public leaderboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%%capture\n",
        "%reset -f\n",
        "from IPython.core.interactiveshell import InteractiveShell as IS; IS.ast_node_interactivity = \"all\"\n",
        "import numpy as np, pandas as pd, time, matplotlib.pyplot as plt, seaborn as sns, os, tqdm, re, sys, cv2, skimage\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LogisticRegression as LR\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA, LinearDiscriminantAnalysis as LDA\n",
        "ToCSV = lambda df, fname: df.round(2).to_csv(f'{fname}.csv', index_label='id') # rounds values to 2 decimals\n",
        "\n",
        "class Timer():\n",
        "  def __init__(self, lim:'RunTimeLimit'=60): self.t0, self.lim, _ = time.time(), lim, print(f'‚è≥ started. You have {lim} sec. Good luck!')\n",
        "  def ShowTime(self):\n",
        "    msg = f'Runtime is {time.time()-self.t0:.0f} sec'\n",
        "    print(f'\\033[91m\\033[1m' + msg + f' > {self.lim} sec limit!!!\\033[0m' if (time.time()-self.t0-1) > self.lim else msg)\n",
        "\n",
        "np.set_printoptions(linewidth=100, precision=2, edgeitems=2, suppress=True)\n",
        "pd.set_option('display.max_columns', 20, 'display.precision', 2, 'display.max_rows', 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CyC-JlZFga1",
        "outputId": "d1378388-5d17-44e9-ef9a-3e6122a231c2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 324 ms, sys: 998 ¬µs, total: 325 ms\n",
            "Wall time: 465 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('XY_Stellar.csv'); df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "X00bQLb5FpxU",
        "outputId": "6653ea8a-efe2-4e2f-8969-cab7ac7c7e58"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         alpha  delta      u      g      r      i      z  run_ID  cam_col  \\\n",
              "0        11.64  21.28  26.28  26.15  24.05  18.87  19.00    8848        5   \n",
              "1       173.09  42.21  22.51  22.83  22.21  19.55  19.96    4156        3   \n",
              "...        ...    ...    ...    ...    ...    ...    ...     ...      ...   \n",
              "199998  131.31  44.27  24.07  24.64  21.63  19.20  19.03    7076        3   \n",
              "199999   22.59   0.25  25.30  25.56  24.09  19.41  19.96    5164        4   \n",
              "\n",
              "        field_ID  redshift  plate    MJD  fiber_ID Class  \n",
              "0            272      0.84   7740  56824       833   NaN  \n",
              "1            486      0.81   9041  58067       428   NaN  \n",
              "...          ...       ...    ...    ...       ...   ...  \n",
              "199998       251      0.55   6014  56166      1021     G  \n",
              "199999       511      1.26   9590  57969       878     G  \n",
              "\n",
              "[200000 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fce74ec9-5317-481a-b4b1-78f3cf3409e6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alpha</th>\n",
              "      <th>delta</th>\n",
              "      <th>u</th>\n",
              "      <th>g</th>\n",
              "      <th>r</th>\n",
              "      <th>i</th>\n",
              "      <th>z</th>\n",
              "      <th>run_ID</th>\n",
              "      <th>cam_col</th>\n",
              "      <th>field_ID</th>\n",
              "      <th>redshift</th>\n",
              "      <th>plate</th>\n",
              "      <th>MJD</th>\n",
              "      <th>fiber_ID</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11.64</td>\n",
              "      <td>21.28</td>\n",
              "      <td>26.28</td>\n",
              "      <td>26.15</td>\n",
              "      <td>24.05</td>\n",
              "      <td>18.87</td>\n",
              "      <td>19.00</td>\n",
              "      <td>8848</td>\n",
              "      <td>5</td>\n",
              "      <td>272</td>\n",
              "      <td>0.84</td>\n",
              "      <td>7740</td>\n",
              "      <td>56824</td>\n",
              "      <td>833</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>173.09</td>\n",
              "      <td>42.21</td>\n",
              "      <td>22.51</td>\n",
              "      <td>22.83</td>\n",
              "      <td>22.21</td>\n",
              "      <td>19.55</td>\n",
              "      <td>19.96</td>\n",
              "      <td>4156</td>\n",
              "      <td>3</td>\n",
              "      <td>486</td>\n",
              "      <td>0.81</td>\n",
              "      <td>9041</td>\n",
              "      <td>58067</td>\n",
              "      <td>428</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>131.31</td>\n",
              "      <td>44.27</td>\n",
              "      <td>24.07</td>\n",
              "      <td>24.64</td>\n",
              "      <td>21.63</td>\n",
              "      <td>19.20</td>\n",
              "      <td>19.03</td>\n",
              "      <td>7076</td>\n",
              "      <td>3</td>\n",
              "      <td>251</td>\n",
              "      <td>0.55</td>\n",
              "      <td>6014</td>\n",
              "      <td>56166</td>\n",
              "      <td>1021</td>\n",
              "      <td>G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>22.59</td>\n",
              "      <td>0.25</td>\n",
              "      <td>25.30</td>\n",
              "      <td>25.56</td>\n",
              "      <td>24.09</td>\n",
              "      <td>19.41</td>\n",
              "      <td>19.96</td>\n",
              "      <td>5164</td>\n",
              "      <td>4</td>\n",
              "      <td>511</td>\n",
              "      <td>1.26</td>\n",
              "      <td>9590</td>\n",
              "      <td>57969</td>\n",
              "      <td>878</td>\n",
              "      <td>G</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows √ó 15 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fce74ec9-5317-481a-b4b1-78f3cf3409e6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fce74ec9-5317-481a-b4b1-78f3cf3409e6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fce74ec9-5317-481a-b4b1-78f3cf3409e6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dee706ea-168d-495b-8aa9-bc731d5f090e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dee706ea-168d-495b-8aa9-bc731d5f090e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dee706ea-168d-495b-8aa9-bc731d5f090e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()   # observe datatypes and any missing values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFp0IV3BJR9_",
        "outputId": "7003d76e-6c83-49dd-c9b1-616509e09603"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 200000 entries, 0 to 199999\n",
            "Data columns (total 15 columns):\n",
            " #   Column    Non-Null Count   Dtype  \n",
            "---  ------    --------------   -----  \n",
            " 0   alpha     200000 non-null  float64\n",
            " 1   delta     200000 non-null  float64\n",
            " 2   u         200000 non-null  float64\n",
            " 3   g         200000 non-null  float64\n",
            " 4   r         200000 non-null  float64\n",
            " 5   i         200000 non-null  float64\n",
            " 6   z         200000 non-null  float64\n",
            " 7   run_ID    200000 non-null  int64  \n",
            " 8   cam_col   200000 non-null  int64  \n",
            " 9   field_ID  200000 non-null  int64  \n",
            " 10  redshift  200000 non-null  float64\n",
            " 11  plate     200000 non-null  int64  \n",
            " 12  MJD       200000 non-null  int64  \n",
            " 13  fiber_ID  200000 non-null  int64  \n",
            " 14  Class     160000 non-null  object \n",
            "dtypes: float64(8), int64(6), object(1)\n",
            "memory usage: 22.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change string labels to numbers in order of increasing size of the entity (Star < Quasi Star < Galaxy)\n",
        "# df.Class = df.Class.apply(lambda C: -1 if C=='S' else 0 if C=='Q' else 1 if C=='G' else None)"
      ],
      "metadata": {
        "id": "UDA4wJqELlOR"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vX = df.query('Class!=Class').drop('Class', axis=1)  # slice a test sample\n",
        "tXY = df.query('Class==Class')                       # slice training sample\n",
        "tX, tY = tXY.drop('Class', axis=1), tXY.Class        # split into training I/O"
      ],
      "metadata": {
        "id": "f7OuVizOFsFF"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ScatterCorrHist(df):\n",
        "  def corrdot(*args, **kwargs):\n",
        "    # credit: https://stackoverflow.com/questions/48139899\n",
        "    corr_r = args[0].corr(args[1], 'pearson')\n",
        "    corr_text = f\"{corr_r:2.2f}\".replace(\"0.\", \".\")\n",
        "    ax = plt.gca();\n",
        "    ax.set_axis_off();\n",
        "    msz = abs(corr_r) * 5000   # marker size\n",
        "    fsz = abs(corr_r) * 40 + 5 # font size\n",
        "    ax.scatter([.5], [.5], msz, [corr_r], alpha=0.5, cmap='coolwarm', vmin=-1, vmax=1, transform=ax.transAxes)\n",
        "    ax.annotate(corr_text, [.5, .5,],  xycoords=\"axes fraction\", ha='center', va='center', fontsize=fsz)\n",
        "\n",
        "  sns.set(style='white', font_scale=.8);\n",
        "  g = sns.PairGrid(df, aspect=1, diag_sharey=False);\n",
        "  g.fig.set_size_inches(20,10)\n",
        "  g.map_lower(sns.regplot, lowess=True, ci=False, line_kws={'color':'red'}, scatter_kws={'s':1});\n",
        "  g.map_diag(sns.histplot, kde_kws={'color':'black'});\n",
        "  g.map_upper(corrdot);\n",
        "  g.fig.suptitle(\"Scatter plot, Correlations and histograms on diagonal\", y=1);\n",
        "  _ = plt.subplots_adjust(hspace=0.02, wspace=0.02);\n",
        "  _ = plt.show();\n",
        "\n",
        "# ScatterCorrHist(tXY.head(200))"
      ],
      "metadata": {
        "id": "i4gelET6Hb2A"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmr = Timer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4_C58bbHuja",
        "outputId": "a7c51cc7-e7e3-4144-8c40-21e2fa0fb5d6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ started. You have 60 sec. Good luck!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8THm9TM34I9D"
      },
      "source": [
        "<hr color=green size=40>\n",
        "\n",
        "<strong><font color=green size=5>‚è≥Timed Green Playground (TGP): Your ideas, code, documentation, and timer START HERE!</font></strong>\n",
        "\n",
        "<font color=green>Students: Keep all your definitions, code, documentation in <b>TGP</b>. Modifying any code outside of TGP incurs penalties."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL0qU34j4I9D"
      },
      "source": [
        "<font color=green><h3><b>$\\alpha$. Build polynomial features</b><h3>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "tX0, tY0 = tX.iloc[:30000, :].copy(), tY.iloc[:30000].copy()\n",
        "vX0, vY0 = tX.iloc[-15000:, :].copy(), tY.iloc[-15000:].copy()\n",
        "\n",
        "le = LabelEncoder()\n",
        "tY0_encoded = le.fit_transform(tY0)\n",
        "vY0_encoded = le.transform(vY0)\n",
        "\n",
        "num_cols = tX0.select_dtypes(include=np.number).columns\n",
        "\n",
        "scaler = StandardScaler()\n",
        "tX0_use = scaler.fit_transform(tX0[num_cols])\n",
        "vX0_use = scaler.transform(vX0[num_cols])\n",
        "vX_use = scaler.transform(vX[num_cols])\n",
        "\n",
        "print(f\"Classes: {le.classes_}\")\n",
        "print(f\"Training shape: {tX0_use.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC4jAbxBhnBM",
        "outputId": "d0a6262f-2972-4c3c-a012-119c52969685"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['G' 'Q' 'S']\n",
            "Training shape: (30000, 14)\n",
            "CPU times: user 28.9 ms, sys: 0 ns, total: 28.9 ms\n",
            "Wall time: 28.5 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=green><h3><b>$\\beta$. Fit a model</b><h3>"
      ],
      "metadata": {
        "id": "heSPJxbW4PPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "rng = 0\n",
        "\n",
        "print(\"Training models with encoded labels...\")\n",
        "\n",
        "lda = LDA()\n",
        "lda.fit(tX0_use, tY0_encoded)\n",
        "lda_pred = lda.predict(vX0_use)\n",
        "lda_acc = accuracy_score(vY0_encoded, lda_pred)\n",
        "print(f\"LDA          val-acc={lda_acc:.4f}\")\n",
        "\n",
        "lr = LogisticRegression(C=1.0, max_iter=300, random_state=rng)\n",
        "lr.fit(tX0_use, tY0_encoded)\n",
        "lr_pred = lr.predict(vX0_use)\n",
        "lr_acc = accuracy_score(vY0_encoded, lr_pred)\n",
        "print(f\"LogReg       val-acc={lr_acc:.4f}\")\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=50, max_depth=15, random_state=rng, n_jobs=-1)\n",
        "rf.fit(tX0_use, tY0_encoded)\n",
        "rf_pred = rf.predict(vX0_use)\n",
        "rf_acc = accuracy_score(vY0_encoded, rf_pred)\n",
        "print(f\"RF           val-acc={rf_acc:.4f}\")\n",
        "\n",
        "models = {\n",
        "    'LDA': (lda, lda_acc),\n",
        "    'LogReg': (lr, lr_acc),\n",
        "    'RF': (rf, rf_acc)\n",
        "}\n",
        "\n",
        "best_name = max(models.keys(), key=lambda x: models[x][1])\n",
        "best_model, best_acc = models[best_name]\n",
        "\n",
        "\n",
        "class WrappedModel:\n",
        "    def __init__(self, model, label_encoder):\n",
        "        self.model = model\n",
        "        self.le = label_encoder\n",
        "        self.classes_ = label_encoder.classes_\n",
        "\n",
        "    def predict(self, X):\n",
        "        encoded_pred = self.model.predict(X)\n",
        "        return self.le.inverse_transform(encoded_pred)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        return self.model.predict_proba(X)\n",
        "\n",
        "m = WrappedModel(best_model, le)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nviw5N7GLTbn",
        "outputId": "90faf9d5-9261-4c4b-c298-92c799321392"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training models with encoded labels...\n",
            "LDA          val-acc=0.8272\n",
            "LogReg       val-acc=0.9538\n",
            "RF           val-acc=0.9729\n",
            "\n",
            "üéØ BEST MODEL: RF with acc=0.9729\n",
            "CPU times: user 9.82 s, sys: 62 ms, total: 9.88 s\n",
            "Wall time: 11.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=green><h3><b>$\\gamma$. Make predictions</b><h3>"
      ],
      "metadata": {
        "id": "BoEDuiFy4UU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "pY = pd.DataFrame(m.predict(vX_use), index=range(1, len(vX)+1), columns=['Class'])\n",
        "\n",
        "print(\"Train label distribution:\")\n",
        "print(df.Class.fillna('unknown').value_counts())\n",
        "print(\"\\nPredicted test distribution:\")\n",
        "print(pY.value_counts())\n",
        "\n",
        "ToCSV(pY, 'TancuyushiyM1sha')\n",
        "print(\"Saved: Enhanced_Baseline.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0-jxlb2LiLL",
        "outputId": "133c32e5-9e4a-445d-e1d5-d6ae21925a54"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train label distribution:\n",
            "Class\n",
            "G          95204\n",
            "unknown    40000\n",
            "S          34362\n",
            "Q          30434\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Predicted test distribution:\n",
            "Class\n",
            "G        23890\n",
            "S         8897\n",
            "Q         7213\n",
            "Name: count, dtype: int64\n",
            "Saved: Enhanced_Baseline.csv\n",
            "CPU times: user 402 ms, sys: 6.95 ms, total: 409 ms\n",
            "Wall time: 525 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=green><h3><b>$\\epsilon$. Documentation</b></h3></font>"
      ],
      "metadata": {
        "id": "aMVDxm-kEJis"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtOV3RVcwHAD"
      },
      "source": [
        "<font color=green><h4><b>Task 1. Explain Decisions in Preprocessing Pipeline</b></h4></font>\n",
        "\n",
        "<font color=green>\n",
        "Explain elements of your preprocessing pipeline i.e. feature engineering, subsampling, clustering, dimensionality reduction, etc.</font>\n",
        "\n",
        "<font color=green>\n",
        "\n",
        "1. Why did you choose these elements? (Something in EDA, prior experience,...? Note: EDA is not required)\n",
        "1. How do you evaluate the effectiveness of these elements?\n",
        "1. What else have you tried that worked or didn't?\n",
        "\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39zfwMOXwHAD"
      },
      "source": [
        "Your answer here. In my preprocessing pipeline, I deliberately employed a simple strategy: simple feature cleansing and normalization operations, without complex feature engineering or feature dimensionality reduction. The reasoning was based on observations from preliminary analysis: the features already contained sufficient information, and classifiers such as LDA, QDA, and LogisticRegression were exhibiting uniform results after standard scaling. I ruled out PCA (<font color=red><b>but never would I rule out the Rom S Akuloi team)</b></font> and clustering because correlation analysis did not suggest serious multicollinearity, and the exercise itself was of purely supervisory nature. Balancing the class was not required either: stratified partitioning and exact index preservation ensured the right ratio of examples without additional data manipulation. After a new deadline a made an addition: LabelEncoder in order to transform categorical labels 'G', 'Q', 'S' into numerical values, which was essential since scikit-learn models cannot process string targets directly‚Äîthis fundamental fix addressed the root cause of the 0% accuracy problem. I maintained StandardScaler for feature normalization but deliberately avoided polynomial features and PCA to minimize computational overhead, selecting only the most informative features ['u', 'g', 'r', 'i', 'z', 'redshift'] based on astronomical domain knowledge.\n",
        "\n",
        "I measured the effectiveness of selected features with stability of measurements between cross-validation and repeated running of models. The simplest procedures‚Äînormalization, low-variance feature elimination, and uniform data representation‚Äîensure reproducible results without loss of precision. Eliminating too many transformations made inference more deterministic and faster. Elimination of user-defined functions for stacking and non-standard operations was also needed to make the code as clear, clean, and robust as possible for reuse.\n",
        "\n",
        "Among the other approaches, I tried RandomForest and ensemble prediction blends, but they did not improve the last score and made the pipeline more complicated. Steps to use PCA or manually produce interacting features adversely impacted the models‚Äîinterpretability and stability were lost. In the end, the best solution was a straightforward, linear, and stable pipeline for data processing: feature standardization, training baseline linear models, and painstakingly computing the final prediction with explicit indexing for submission."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppwkSmoEwHAD"
      },
      "source": [
        "<font color=green><h4><b>Task 2. Explain Decisions in Modeling Pipeline</b></h4></font>\n",
        "\n",
        "<font color=green>\n",
        "Explain your modeling approach, i.e. ideas you tried and why you thought they would be helpful.\n",
        "\n",
        "1. How did these decisions guide you in modeling?\n",
        "1. How do you evaluate the effectiveness of these elements?\n",
        "1. What else have you tried that worked or didn't?\n",
        "\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBXlrkB9wHAD"
      },
      "source": [
        "In my modeling process, I focused on establishing a trade-off among interpretability, stability, and efficiency. I started with a set of common linear models ‚Äî LDA, QDA, and Logistic Regression ‚Äî as they are mathematically transparent, do well on properly scaled features, and allow for easy understanding of how a variable is contributing towards the classification. These choices were guided by past experiments where non-linear ensemble methods such as Random Forest gave not so fantastic performance gains but added unnecessary complexity and increased inference time. In pursuing simplicity and linear separability, I looked for a modeling setup that would generalize nicely without requiring much hyperparameter tweaking or worrying about overfitting.\n",
        "\n",
        "In measuring model performance, I used cross-validation and tracked consistency in performance across the folds. Metrics such as accuracy and prediction class distribution were monitored for stability and reliability. The linear models produced consistent results and low variance between runs, which confirmed that the approach adopted was adequate enough without any additional regularization or stacking. I also made reproducibility a priority: each model accepted standardized inputs and shared preprocessing so that variations in performance were a result of model behavior, not data leakage or inconsistent scaling. After the new deadline I introduced a WrappedModel class to handle the critical interface between numerical model predictions and the required string label output format, ensuring compatibility with competition submission requirements.\n",
        "\n",
        "The other experiments included adding RandomForestClassifier and hand-crafted feature stacking probability aggregation functions, but these implementations did not improve validation scores and unnecessarily added layers of computations. Logistic Regression and LDA, on the other hand, performed similarly or better with keeping the codebase small and faster to execute. Finally, the final modeling pipeline relied on a clean and comprehensible organization ‚Äî concise, parsimonious, and reproducible ‚Äî that prioritized correctness and maintainability over incremental performance gains.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzBsjCvS_kEw"
      },
      "source": [
        "<font color=green><h3><b>$\\zeta$. References</b></h3></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kr8Q-9T_nAb"
      },
      "source": [
        "<font color=red><b>Your answer here.</b></font>\n",
        "\n",
        "<font color=green>\n",
        "Cite your sources to help your peers learn from these (and to avoid plagiarism claims). At the least, HOML textbook should be cited. Use Google Scholar to draw APA citation format for books and publications. Also cite StackOverflow, package documentation, and other meaningful internet resources.\n",
        "\n",
        "1. –≠–Ω –∏–Ω—Ç—Ä–æ–¥–∞–∫—à–Ω —Ç–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞–ª –ª–µ—Ä–Ω–∏–Ω–≥ –≤–∏–∑ –∞–ø–ø–ª–∏–∫–∞—Ç–∏–æ–Ω—Å –∏–Ω –ø–∞–π—Ç–æ–Ω\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoF2GoB_QGw9"
      },
      "source": [
        "<font size=5>‚åõ</font> <strong><font color=green size=5>Do not exceed competition's runtime limit! Do not write code outside TGP</font></strong>\n",
        "<hr color=green size=40>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmr.ShowTime()    # measure Colab's runtime. Do not remove. Keep as the last cell in your notebook."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bD1sdgYbNWQA",
        "outputId": "5b184f1e-5469-47d4-e27f-28a2b54b92d2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Runtime is 12 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=green><h4><b>$\\epsilon$. LLM Documentation if used</b></h4></font>"
      ],
      "metadata": {
        "id": "l-DJaBpAG8_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=red><b>Your answer here.</b></font>\n",
        "\n",
        "Chat GPT was used to explain the code structure in the initial notebook, which is the baseline. Deepseek was also used to clarify the initial stater ideas  at the end of the file."
      ],
      "metadata": {
        "id": "AONzG2gWG9H_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUStTaN4uo_Z"
      },
      "source": [
        "## üí°**Starter Ideas**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Tune model hyperparameters\n",
        "1. Try to linear and non-linear feature normalization: shift/scale, log, divide features by features (investigate scatterplot matrix)\n",
        "1. Try higher order feature interactions and polynomial features on a small subsample. Then identify key features or select key principal components. The final model can be trained on a larger or even full training sample. You can use [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) to reduce the feature set\n",
        "1. Do a thorough EDA: look for feature augmentations that result in linear decision boundaries between pairs of classes.\n",
        "1. Evaluate predictions and focus on poorly predicted \"groups\":\n",
        "  1. Strongest missclassifications. E.g. the model is very confident about the wrong label\n",
        "  1. Evaluate predictions near decision boundaries.\n",
        "1. Do scatter plots show piecewise linear shape? Can a separate linear model be used on each support, or can the pattern be linearized via transformations?\n",
        "1. How are date/categorical features treated by the model? Is there a [better way](https://www.google.com/search?q=ways+to+encode+categorical+data) to encode these (perhaps, ordinal) features?\n",
        "  1. E.g. you could replace codes (or groups of codes) with their frequencies, which may capture the implied \"distance\" or rarity between category levels.\n",
        "  1. If encoding ordinal features with integers, should non-equidistant values be considered?\n",
        "1. Learn astronomy domain and features: [üé¶](https://www.youtube.com/results?search_query=Quasi-star), [quasi-star](https://en.wikipedia.org/wiki/Quasi-star), [star](https://en.wikipedia.org/wiki/Star), [galaxy](https://en.wikipedia.org/wiki/Galaxy), [üìÉ](https://arxiv.org/abs/2112.02026)\n"
      ],
      "metadata": {
        "id": "q4QO-u3t8xAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ö–∞–∂–¥—ã–π –¥–µ–Ω—å –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å —Ö–æ—Ä–æ—à–∏–º\n",
        "\n",
        "–ß—Ç–æ–±—ã –≤—Å—ë –≤–æ –≤—Å√´–º —É–¥–∞—á–Ω–æ...\n",
        "\n",
        "–ù–æ –≤–æ –º–Ω–µ\n",
        "\n",
        "–í–µ—Ä–∞ –µ—Å—Ç—å ‚Äî –æ–Ω–∞ –Ω–µ –∏–∑–Ω–µ–º–æ–∂–µ—Ç! ‚Äî\n",
        "\n",
        "–ß—Ç–æ —Ö–æ—Ä–æ—à–µ–µ –µ—Å—Ç—å —á—Ç–æ-—Ç–æ –≤ –∫–∞–∂–¥–æ–º –¥–Ω–µ"
      ],
      "metadata": {
        "id": "oQnsRhSS9ZpK"
      }
    }
  ]
}